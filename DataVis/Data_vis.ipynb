{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "from Results_tables.experiment import text_to_df\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# mpl.rc('font', family='serif', serif='cmr10')\n",
    "# mpl.rc('axes.formatter', use_mathtext=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:22.841550945Z",
     "start_time": "2023-05-14T21:16:22.747936492Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_line_plot(name, df, desc, numerical_x_axis=False, pretrained=True, root='./', y_range=None, tpi=False,\n",
    "                       font_size=12, draw_zero=False, y_axis_label=\"mIoU Score\", broke=False):\n",
    "    print(name + \": \" + desc)\n",
    "    if not Path(root).exists(): Path(root).mkdir()\n",
    "    if not Path(f'{name}').exists(): Path(f'{name}').mkdir()\n",
    "    if not Path(f'no_legend/{name}').exists(): Path(f'no_legend/{name}').mkdir(parents=True)\n",
    "    # Define the data\n",
    "    models = df['Model']\n",
    "\n",
    "    first_miou = [df.iloc[i, 1:5].values.tolist() for i in range(len(df))]\n",
    "    second_miou = [df.iloc[i, 5:9].values.tolist() for i in range(len(df))]\n",
    "    first_miou = [list(map(float, i)) for i in first_miou]\n",
    "    second_miou = [list(map(float, i)) for i in second_miou]\n",
    "\n",
    "    x_axis_labels = []\n",
    "    if numerical_x_axis:\n",
    "        x_axis_labels = [2.5, 5, 25, 50]\n",
    "    elif tpi:\n",
    "        x_axis_labels = ['', '2.5->5%', '5->25%', '25->50%']\n",
    "    else:\n",
    "        x_axis_labels = ['2.5%', '5%', '25%', '50%']\n",
    "\n",
    "    # Create a figure and an axis object\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    # if broke:\n",
    "    #     from brokenaxes import brokenaxes\n",
    "    #     if name == \"Piazza\":\n",
    "    #         if draw_zero:\n",
    "    #             fig = plt.figure(figsize=(9,5))\n",
    "    #             ax = brokenaxes(ylims=((-50,-40),(-15,10)))\n",
    "    #         else:\n",
    "    #             fig = plt.figure(figsize=(9,5))\n",
    "    #             ax = brokenaxes(ylims=((100,20),(40,80)))\n",
    "\n",
    "    # Plot the data\n",
    "    colors = ['#377eb8', '#4daf4a', '#e41a1c', '#984ea3', '#ff7f00']\n",
    "    markers = ['o', 's', '^', '*', 'D']\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for i in range(len(models)):\n",
    "        if pretrained:\n",
    "            first_suffix = '(pretrained)'\n",
    "            second_suffix = '(random)'\n",
    "        else:\n",
    "            first_suffix = '(Validation)'\n",
    "            second_suffix = '(50% Holdout)'\n",
    "\n",
    "        first_label = models[i] + ' ' + first_suffix\n",
    "        second_label = models[i] + ' ' + second_suffix\n",
    "        if first_label not in [f'Random Forest {first_suffix}', f'XGBoost {first_suffix}']:\n",
    "            handle, = ax.plot(x_axis_labels, first_miou[i], color=colors[i % len(colors)],\n",
    "                              marker=markers[i % len(markers)], label=first_label, linewidth=2, markersize=6)\n",
    "            handles.append(handle)\n",
    "            labels.append(first_label)\n",
    "\n",
    "        handle, = ax.plot(x_axis_labels, second_miou[i], '--', color=colors[i % len(colors)],\n",
    "                          marker=markers[i % len(markers)], label=second_label, linewidth=1.5, markersize=6)\n",
    "        handles.append(handle)\n",
    "        labels.append(second_label)\n",
    "\n",
    "    if draw_zero: ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Set the x-axis and y-axis labels\n",
    "    x_axis_label = 'Training Percentage Increase (not to scale)' if tpi else 'Training Percentage (not to scale)'\n",
    "    ax.set_xlabel(x_axis_label, fontsize=font_size)\n",
    "    ax.set_ylabel(y_axis_label, fontsize=font_size)\n",
    "\n",
    "    if y_range:\n",
    "        if name == \"Bagni Nerone\":\n",
    "            if draw_zero: ax.set_ylim(-60, 40)\n",
    "            else: ax.set_ylim(10, 100)\n",
    "            # if draw_zero: ax.set_ylim(-60, 40)\n",
    "            # else: ax.set_ylim(0, 100)\n",
    "        if name == \"Church\":\n",
    "            if draw_zero: ax.set_ylim(-50, 70)\n",
    "            else: ax.set_ylim(10, 100)\n",
    "        if name == \"Lunnahoja\":\n",
    "            if draw_zero: ax.set_ylim(-50, 50)\n",
    "            else: ax.set_ylim(10, 100)\n",
    "        if name == \"Montelupo\":\n",
    "            if draw_zero: ax.set_ylim(-60, 60)\n",
    "            else: ax.set_ylim(10, 100)\n",
    "        if name == \"Monument\":\n",
    "            if draw_zero: ax.set_ylim(-30, 30)\n",
    "            else: ax.set_ylim(10, 90)\n",
    "        if name == \"Piazza\":\n",
    "            if draw_zero: ax.set_ylim(-50, 10)\n",
    "            else: ax.set_ylim(10, 90)\n",
    "        elif y_range != True:\n",
    "            ax.set_ylim(y_range)\n",
    "\n",
    "    if numerical_x_axis:\n",
    "        ax.set_xticks(x_axis_labels)\n",
    "        # ax.set_xticklabels([f\"{x}%\" for x in x_axis_labels], fontsize=10)\n",
    "        # ax.set_xlim(0, 55)\n",
    "\n",
    "    # Set the plot title and legend\n",
    "    # ax.set_title(f'{name}:\\nmIoU scores for different models and pretraining percentages', fontsize=14, fontweight='bold')\n",
    "    ax.legend(handles, labels, fontsize=10, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "    # Set the tick label font size\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    # Set the background color of the plot\n",
    "    # ax.set_facecolor('#f0f0f0')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{root}{name} {desc}.pdf')\n",
    "    plt.savefig(f'{name}/{name} {desc}.pdf')\n",
    "    ax.legend().remove()\n",
    "    plt.savefig(f'no_legend/{name}/{name} {desc}.pdf')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "text = \"\"\"Pointnet++\t32.12\t31.96\t31.59\t31.96\t32.12\t31.96\t31.59\t31.96\n",
    "KPConv\t73\t92.8\t95.27\t96.34\t\t91.88\t95.04\t96.32\n",
    "Point-Transformer\t89.09\t83.08\t72.39\t76.88\t86.6\t72.04\t72.05\t43.32\n",
    "Random Forest\t\t\t\t\t77.44\t89.4\t92.56\t95.12\n",
    "XGBoost\t\t\t\t\t76.08\t84.52\t92.5\t91.98\"\"\"\n",
    "scene = \"Bagni Nerone\"\n",
    "desc = \"Validation mIoU\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = text_to_df(text)\n",
    "generate_line_plot(scene, df, desc, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = text_to_df(\"\"\"Pointnet++\t31.97\t31.96\t31.96\t31.96\t31.96\t31.96\t31.96\t31.96\n",
    "KPConv\t43.84\t66.28\t89.33\t93.94\t36.54\t90.24\t92.23\t93.86\n",
    "Point-Transformer\t38.98\t70.38\t15.05\t76.7\t63.75\t63.75\t63.75\t63.75\n",
    "Random Forest\t\t\t\t\t69.79\t84.93\t94.4\t95.21\n",
    "XGBoost\t\t\t\t\t80.85\t85.91\t95.27\t91.68\"\"\")\n",
    "generate_line_plot(\"Bagni Nerone\", df, \"50% Holdout mIoU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bar plot\n",
    "Bagni Nerone as a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_bar_plot(name, df, desc):\n",
    "    models = df.Model\n",
    "\n",
    "    pretrained_miou = [df.iloc[i, 1:5].values.tolist() for i in range(len(df))]\n",
    "    random_miou = [df.iloc[i, 5:9].values.tolist() for i in range(len(df))]\n",
    "    pretrained_miou = [list(map(float, i)) for i in pretrained_miou]\n",
    "    random_miou = [list(map(float, i)) for i in random_miou]\n",
    "\n",
    "    x_labels = ['2.5% (pretrained)', '5% (pretrained)', '25% (pretrained)', '50% (pretrained)', '2.5% (random)',\n",
    "                '5% (random)', '25% (random)', '50% (random)']\n",
    "    x_positions = np.arange(len(x_labels))\n",
    "\n",
    "    # Define the colors and patterns for each model\n",
    "    colors = ['#377eb8', '#4daf4a', '#e41a1c', '#984ea3', '#ff7f00']\n",
    "    patterns = ['-', 'x', '+', '\\\\', '/']\n",
    "\n",
    "    # Create a figure and an axis object\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the data\n",
    "    for i, model in enumerate(models):\n",
    "        # Plot the pretrained data\n",
    "        ax.bar(x_positions[:4] + i * 0.15, pretrained_miou[i], color=colors[i % len(colors)],\n",
    "               width=0.15, label=model + ' (pretrained)')\n",
    "        # Plot the random data\n",
    "        ax.bar(x_positions[4:] + i * 0.15, random_miou[i], color=colors[i % len(colors)],\n",
    "               hatch=patterns[i % len(patterns)], width=0.15, label=model + ' (random)')\n",
    "\n",
    "    # Set the x-axis and y-axis labels\n",
    "    ax.set_xlabel('Training Percentage (Pretrained / Random)', fontsize=12)\n",
    "    ax.set_ylabel('mIoU Score', fontsize=12)\n",
    "\n",
    "    # Set the x-axis tick labels and limits\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(x_labels, fontsize=10)\n",
    "    ax.set_xlim(-0.5, len(x_labels) - 0.5)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set the y-axis limits and tick labels\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
    "    ax.set_yticklabels(['0\\%', '20\\%', '40\\%', '60\\%', '80\\%', '100\\%'], fontsize=10)\n",
    "\n",
    "    # Set the plot title and legend\n",
    "    ax.set_title('Bagni Nerone:\\nmIoU scores for different models and pretraining percentages', fontsize=14,\n",
    "                 fontweight='bold')\n",
    "    ax.legend(fontsize=10, loc='upper left', bbox_to_anchor=(1., 1))\n",
    "\n",
    "    # Set the tick label font size\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    # Set the background color of the plot\n",
    "\n",
    "    # ax.set_facecolor('#f0f0f0')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{name} {desc} (column).pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_bar_plot(\"Bagni Nerone\", df, \"Validation mIoU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mIoU Tables\n",
    "Generates the mIoU results for all scenes and across pretrained and randomly initialised models for both the standard and 50% holdout validations.\n",
    "\n",
    "## Missing data\n",
    "- KPConv is missing 2.5% random initialisaiton on Bagni Nerone.\n",
    "\n",
    "- XGBoost is missing 50% holdout Random Initialisation Church _(this could be recreated without a huge amount of effort)_\n",
    "- Point transformer is missing 2.5% random initialisation on Monument.\n",
    "\n",
    "## Unexpected results\n",
    "- Pointnet++ Bagni Nerone: Validation/mIoU is very low and V/mAcc hovers around 50% suggesting the model was unable to learn anything and predicted a single class during validation (and also training).\\\n",
    "__Go check this in wandb__\\\n",
    "Training/mIoU did not exceed 50% barring the 2.5% experiment likely due to the model predicting randomly rather than it magically having learned something (or it could be because the tiny amount of training data was learnable to some extent).\n",
    "\n",
    "- Point Transformer Bagni Nerone:\n",
    "Sudden drop in mIoU on 50% random initialisaiton. Model rapidly collapsed to only predicting a single class _(confirm this in wandb because it's different to P++ above)_\\\n",
    "Looking at the performance on the holdout set there is always the same performance suggesting that the model in fact did now learn anything meaningful with increased training data. This supports the hypothesis that Transformers require significantly more data to train _(ummm why?)_\\\n",
    "Similarly why is there this big up-down spike on the 25% pretrained holdout.\n",
    "\n",
    "- Pretrained 50% holdout Church:\n",
    "Apparently I wanted to look at the performance graph on the pretrained holdout being very similar?\n",
    "\n",
    "- Point Transformer Church:\n",
    "Why is the performance exactly the same (and shit) on the randomly initialised 50% holdout and then suddenly JUMPS up?\n",
    "\n",
    "- Pointnet++ Lunnahoja:\n",
    "Really bad performance except on the pretrained 5% (both validation and holdout). Maybe this happened to provide __just the right data__ for the model to learn?\\\n",
    "Lunnahoja is a particularly difficult scene to hypothesise about the model performance due to the noisy ground truth labels. The affect of label noise and methods for mitigating it during the training of classifiers is an open problem \\cite{https://ai.googleblog.com/2020/08/understanding-deep-learning-on.html} Perhaps in future we should have relabelled the noise ourselves _(put this in the datasets chapter)_\n",
    "\n",
    "## Montelupo Problems\n",
    "Random initialisation 2.5% (and 5%) is weirdly poor for KPConv and Point transformer when Pointnet++ somehow manages to get good results??? It's probably more likely that pointnet++ mostly randomly guessed things here but then again the tree methods manage really well.... Might need to visualise this.\n",
    "\n",
    "## Monumental Problems\n",
    "As monument is such a simplistic model, the mIoU score becomes unhelpful as there may be very few examples of one of the classes. If the model then makes even a small number of mistakes it has an outsized effect on the results. Whilst this is a benefit typically, in this case examining the Acc and F1 score reveals that the model was near 100% accurate. _(Go back and quickly explain mIoU and F1 scores in experimental design I think (or maybe background)_."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import mIoU as mIoU_py\n",
    "\n",
    "print(\"hello\")\n",
    "for e in mIoU_py.experiments:\n",
    "    df = text_to_df(e.first)\n",
    "    generate_line_plot(e.scene, df, \"Validation mIoU (use)\", root='mIoU_graphs/', y_range=True)\n",
    "\n",
    "    df = text_to_df(e.second)\n",
    "    generate_line_plot(e.scene, df, \"50% Holdout mIoU (use)\", root='mIoU_graphs/', y_range=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:58.576122509Z",
     "start_time": "2023-05-14T21:16:53.843694304Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretraining Improvement\n",
    "Improvement in mIoU by pretraining. \\\n",
    "`pretraining mIoU - random intialisation mIoU`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import pretraining_improvement\n",
    "\n",
    "for e in pretraining_improvement.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Pretraining Improvement (use)\", pretrained=False, root='pretraining_improvement/', draw_zero=True, y_range=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:49.447590013Z",
     "start_time": "2023-05-14T21:16:47.012161030Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Holdout Difference\n",
    "`50% holdout - validation mIoU`\n",
    "Shows the difference between the 50% holdout and the mIoU over the entire unseen region.\n",
    "Negative numbers means the 50% Holdout score was worse (ie the hypothesis that some training data is easier than others is upheld).\n",
    "\n",
    "This happens when the \"extra\" points (eg for a 5% training there is an extra 45% of the scene to evaluate on) are \"easy\" to predict and unfairly skews the performance. This could happen for instance where there is a large simple region (eg ground plane) in these \"\"extra\"\" points that is providing a \"\"buffer\"\" for he performance.\n",
    "\n",
    "In theory there should be a 0% difference on the 50% columns because they should be literally the same. these discrepancies are concerning.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import holdout_diff\n",
    "\n",
    "for e in holdout_diff.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Holdout Difference (use)\", pretrained=True, root='holdout_difference/', draw_zero=True, y_range=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:44.078158563Z",
     "start_time": "2023-05-14T21:16:41.597236466Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Effective mIoU\n",
    "`mIoU * holdout% + 100*training%`\n",
    "Gives the effective labelling performance for a real world application.\n",
    "\n",
    "That is to say in the real world we only care about the overall effctive labelling of a scene. i.e. The user has labelled some \"\"training%\"\" which can be assumed as \"\"correct\"\". The model has then labelled some \"\"Holdout%\"\" and achieved some performance on this. Combing these, what is the overall labelling performance compared to having labelled everything by hand. Alternatively we could consider this as \"\"what % still remains to be corrected?\"\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import mIoU_effective\n",
    "\n",
    "for e in mIoU_effective.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Effective mIoU\", root='effective_mIoU/', y_range=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:39.869140605Z",
     "start_time": "2023-05-14T21:16:37.437513735Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mIoU Improvement via Training %\n",
    "An interesting observation is the relationship between increasing the training % and the overall mIoU performance.\n",
    "\n",
    "For it to be efficient to increase the training% by X%, we expect at least X% increase in the effective performance.\n",
    "\n",
    "How to show this? We could look just at the increase in performance but that doesn't account for the AMOUNT of increased training data being different.\n",
    "Perhaps we subtract the amount of training data added. In theory an increase of X% training data should result in an increase by X% but what about times where the model was ALREADY very good? if its already predicting perfectly adding mroe training data won't help this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import training_percentage_improvement\n",
    "\n",
    "for e in training_percentage_improvement.experiments:\n",
    "    df = text_to_df(e.first)\n",
    "    generate_line_plot(e.scene, df, \"Validation Improvement via Training %\", root='training_percentage_improvement/',\n",
    "                       tpi=True, draw_zero=True)\n",
    "\n",
    "    df = text_to_df(e.second)\n",
    "    generate_line_plot(e.scene, df, \"50% Holdout Improvement via Training %\", root='training_percentage_improvement/',\n",
    "                       tpi=True, draw_zero=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Effective mIoU improvement by training %\n",
    "The increase in effective mIoU over the previous training percentage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import effective_training_percentage_improvement\n",
    "\n",
    "for e in effective_training_percentage_improvement.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Effective mIoU Improvement via Training %\", pretrained=False, root='effective_mIoU_training_percentage_improvement/', tpi=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Effective training % improvement over labels\n",
    "The increase in effective mIoU above the increased labelling percentage.\n",
    "If the result of this is positive then adding more labelling at the start resulted in a better overall labelling than if you had just labelled less, run the network, and then finished the labelling afterwards.\n",
    "`mIoU effective increase - additional labelling %`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import effective_training_percentage_improvement_over_labels\n",
    "\n",
    "for e in effective_training_percentage_improvement_over_labels.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Effective mIoU Improvement via Training % over labels\", pretrained=False, root='effective_mIoU_training_percentage_improvement_over_labels/', tpi=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Effective mIoU Improvement\n",
    "`effective mIoU - base mIoU`\n",
    "As the user labels a greater proportion of the data, so too does the influence of the model predictions on the overall labelling performance drop.\n",
    "\n",
    "This metric measures the difference between the effective performance and the prediction performance.\n",
    "\n",
    "Where we see big jumps in this (typically around 50% mark) we can say that the"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import mIoU_effective_improvement\n",
    "\n",
    "for e in mIoU_effective_improvement.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Effective mIoU_improvement\", pretrained=True, root='effective_mIoU_improvement/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mIoU improvement over pointnet++"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import mIoU_improvement_pointnet\n",
    "\n",
    "for e in mIoU_improvement_pointnet.experiments:\n",
    "    df = text_to_df(e.first)\n",
    "    generate_line_plot(e.scene, df, \"Validation Improvement over Pointnet++\", root='improvement_over_pointnet++/',\n",
    "                       )\n",
    "\n",
    "    df = text_to_df(e.second)\n",
    "    generate_line_plot(e.scene, df, \"50% Holdout Improvement over Pointnet++\", root='improvement_over_pointnet++/',\n",
    "                       )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mIoU improvement over Random Forests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import mIoU_improvement_RF\n",
    "\n",
    "for e in mIoU_improvement_RF.experiments:\n",
    "    df = text_to_df(e.first)\n",
    "    generate_line_plot(e.scene, df, \"Validation Improvement over RF\", root='improvement_over_RF/',\n",
    "                       )\n",
    "\n",
    "    df = text_to_df(e.second)\n",
    "    generate_line_plot(e.scene, df, \"50% Holdout Improvement over RF\", root='improvement_over_RF/',\n",
    "                       )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Total Labelling Effort"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Results_tables import total_labelling_effort\n",
    "\n",
    "for e in total_labelling_effort.experiments:\n",
    "    df = text_to_df(e.vals)\n",
    "    generate_line_plot(e.scene, df, \"Total Labelling Effort\", root='total_labelling_effort/', y_axis_label=\"Total labelling effort % (←)\",y_range=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T21:16:33.304317698Z",
     "start_time": "2023-05-14T21:16:30.828613779Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
